{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951b664d",
   "metadata": {
    "id": "951b664d"
   },
   "source": [
    "#  Постановка задачи\n",
    "\n",
    "Цель задания - раскрасить матрёшку с помощью SDS лосса.\n",
    "\n",
    "Для этого дан скрипт matryoshka.py, который позволяет рисовать матрешку с заданного ракурса.\n",
    "\n",
    "Помимо этого, скрипт содержит модуль Texture, который в качестве обучаемых параметров содержит текстуру матрешки.\n",
    "\n",
    "Используя диффузионную модель Deepfloyd-IF, вы настроите параметры текстуры. Внешний вид матрёшки будет определять текстовый промпт. Для удобства, мы предподсчитали представление одного промпта, но вы также сможете выбрать и свой промпт."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf3a534a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmDHjSiLXRkM",
    "outputId": "4ee36857-37df-4aaa-a297-1fd5ec2a2866"
   },
   "source": [
    "! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21e3d423",
   "metadata": {
    "id": "QRLmWjcsXyLp"
   },
   "source": [
    "! pip install --upgrade \\\n",
    "  diffusers~=0.16 \\\n",
    "  safetensors~=0.3 \\\n",
    "  sentencepiece~=0.1 \\\n",
    "  accelerate~=0.18 \\\n",
    "  bitsandbytes~=0.38 \\\n",
    "  torch~=2.0 -q"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e24fb4c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwaqZlljXR0l",
    "outputId": "b8433acf-430e-44f5-c355-e982d1fe22dc"
   },
   "source": [
    "# see https://huggingface.co/docs/hub/security-tokens\n",
    "! huggingface-cli login --token YOUR_HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4d9a2",
   "metadata": {
    "id": "5ee4d9a2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import imageio\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import Video\n",
    "\n",
    "from transformers import T5EncoderModel\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "from matryoshka import Texture, render, calculate_normals, calculate_soft_shadow\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "deepfloyd_model = \"DeepFloyd/IF-I-M-v1.0\"\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "flush()\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f15b0",
   "metadata": {
    "id": "715f15b0"
   },
   "source": [
    "Что есть в файлике?\n",
    "\n",
    "Класс Texture\n",
    "\n",
    "Метод render, который принимает\n",
    "1. Позицию камеры\n",
    "2. Направление камеры\n",
    "3. Функцию, которая красит точки,\n",
    "4. Текстуру (опционально)\n",
    "5. Источник освещения (опционально)\n",
    "\n",
    "Вспомогательные методы calc_normals, calculate_soft_shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577920b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "f577920b",
    "outputId": "48d3bb8f-1ebc-4fe3-eefe-7690ef5fe0d2"
   },
   "outputs": [],
   "source": [
    "camera_origin = torch.as_tensor([[1, 3., 1.5]], device=device)\n",
    "camera_target = torch.as_tensor([[0., 0., 1.0]], device=device)\n",
    "camera_direction = camera_target - camera_origin\n",
    "\n",
    "def get_pixel_normals(points, texture, light_source):\n",
    "    return 0.5 * (calculate_normals(points) + 1.)\n",
    "\n",
    "rendered_normals = render(camera_origin, camera_direction, get_pixel_normals, resolution=512)\n",
    "\n",
    "plt.imshow(rendered_normals[0].cpu())\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76573c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "d76573c9",
    "outputId": "dda1004c-00aa-4c93-b753-358345d62546"
   },
   "outputs": [],
   "source": [
    "matryoshka_texture = Texture(texture_grid=torch.rand(1, 3, 64, 64),\n",
    "                             background_color=torch.as_tensor([0., 0.5, 0.3])).to(device)\n",
    "\n",
    "def get_texture(points, texture, light_source):\n",
    "    return texture(points)\n",
    "\n",
    "rendered_albedo = render(camera_origin, camera_direction, get_texture, matryoshka_texture, resolution=512)\n",
    "\n",
    "plt.imshow(rendered_albedo[0].detach().cpu())\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf62736",
   "metadata": {
    "id": "ebf62736"
   },
   "source": [
    "Сделаем чуть интереснее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94501484",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "94501484",
    "outputId": "c6903474-516d-4b8f-af9f-17b238425181"
   },
   "outputs": [],
   "source": [
    "def get_pixel_colors(points, texture, light_source):\n",
    "    albedo = texture(points)\n",
    "    normals = calculate_normals(points)\n",
    "    light_dir = F.normalize(light_source - points, dim=-1)\n",
    "    # Lambert's cosine law\n",
    "    shadow_coefficient = (normals * light_dir).sum(-1, keepdim=True).clamp(0.)\n",
    "    # Does the point see the light source?\n",
    "    light_rays = {'origins': points,\n",
    "                  'directions': F.normalize(light_source - points, dim=-1)}\n",
    "    in_shadow = calculate_soft_shadow(light_rays)\n",
    "    ambient_light = 0.2\n",
    "    return (albedo * (ambient_light + shadow_coefficient * in_shadow)).clamp(0., 1.)\n",
    "\n",
    "light_source = 3. * torch.as_tensor([2.0, 1.0, 1.0]).to(device)\n",
    "rendered_image = render(\n",
    "    camera_origin,\n",
    "    camera_direction,\n",
    "    get_pixel_colors,\n",
    "    matryoshka_texture,\n",
    "    light_source,\n",
    "    resolution=512\n",
    ")\n",
    "\n",
    "plt.imshow(rendered_image[0].detach().cpu())\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78498412",
   "metadata": {
    "id": "78498412"
   },
   "outputs": [],
   "source": [
    "def render_validation_frames(get_pixel_colors, texture=None, light_source=None, n_frames=180, chunk_size=8, **kwargs):\n",
    "    time = torch.linspace(0, 1, n_frames)\n",
    "    # camera flies around the scene center\n",
    "    camera_origins = 3. * torch.stack(\n",
    "        [(2 * torch.pi * time).cos(),\n",
    "         (2 * torch.pi * time).sin(),\n",
    "         torch.full_like(time, 0.5)], dim=1\n",
    "    ).to(device)\n",
    "    camera_target = torch.as_tensor([0., 0., 1.]).to(device)\n",
    "    camera_directions = camera_target - camera_origins\n",
    "    # render images in chunks\n",
    "    light_source = 4. * torch.as_tensor([1.0, 0.0, 1.0]).to(device)\n",
    "    images = []\n",
    "    for camera_origins_batch, camera_directions_batch in zip(\n",
    "        torch.split(camera_origins, chunk_size),\n",
    "        torch.split(camera_directions, chunk_size)\n",
    "    ):\n",
    "        images_batch = render(camera_origins_batch,\n",
    "                              camera_directions_batch,\n",
    "                              get_pixel_colors,\n",
    "                              texture,\n",
    "                              light_source,\n",
    "                              resolution=512,\n",
    "                              **kwargs).clamp(0., 0.999)\n",
    "        images_batch = (256 * images_batch).floor().to(torch.uint8)\n",
    "        images_batch = images_batch.cpu().numpy()\n",
    "        images.append(images_batch)\n",
    "    return np.concatenate(images)\n",
    "\n",
    "def save_video(frames, filename):\n",
    "    writer = imageio.get_writer(filename, fps=30)\n",
    "    for frame in images:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847924e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533,
     "resources": {
      "http://localhost:8080/test_render.mp4": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "847924e6",
    "outputId": "0e5ef2f6-562b-4a7e-92d2-41a4c45b26f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = render_validation_frames(get_pixel_colors, matryoshka_texture)\n",
    "save_video(images, 'init_render.mp4')\n",
    "\n",
    "Video(\"init_render.mp4\", width=512, height=512, html_attributes='loop autoplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e720d0",
   "metadata": {},
   "source": [
    "Почистим память для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6984c13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6984c13",
    "outputId": "a09150ef-c151-4784-849d-a8c25155d71a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# посчитим память от ненужных объектов\n",
    "del camera_origin\n",
    "del camera_target\n",
    "del camera_direction\n",
    "del matryoshka_texture\n",
    "del rendered_normals\n",
    "del rendered_albedo\n",
    "del rendered_image\n",
    "flush()\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46b5be",
   "metadata": {
    "id": "bd46b5be"
   },
   "source": [
    "# Представления промпта\n",
    "\n",
    "Ниже мы подгружаем кодировщик T5 и вычисляем представления промпта. Чтобы воспольззоваться предподсчитанными, можно пропустить следующие три ячейки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f09e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "referenced_widgets": [
      "1e837aff804e4fba9740fed239165ae6",
      "874c19d1eac04e69ad14867c36eda1c7",
      "893b2303e9684ff48938cde3406b41da",
      "f287b1f5940f447697ffb1d1bf8d7bdb",
      "15b26e55b9424ccc87b4eebe547ef8b8",
      "083b67069095484f84b0377d21801c1e",
      "12c6025145ec402e89baaca6f8c470aa",
      "2a519a4bd32346cfaa604df2dd41eb54",
      "0f6d14ec2c814656b7c02c1ba64080b4",
      "94fcd7af3a464cbd905b57817aa324c4",
      "1c2de2ddf2734412995b6165bc43dfd3"
     ]
    },
    "id": "231f09e1",
    "outputId": "a986a14d-5996-4397-fac7-4e67d3a8bf41"
   },
   "outputs": [],
   "source": [
    "text_encoder = T5EncoderModel.from_pretrained(\n",
    "    deepfloyd_model,\n",
    "    subfolder=\"text_encoder\",\n",
    "    device_map=\"auto\",\n",
    "    variant=\"8bit\",\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    deepfloyd_model,\n",
    "    text_encoder=text_encoder, # pass the previously instantiated 8bit text encoder\n",
    "    unet=None,\n",
    "    device_map=\"balanced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225f849",
   "metadata": {
    "id": "4225f849"
   },
   "outputs": [],
   "source": [
    "prompt = \"Astronaut in a form of matryoshka doll\"\n",
    "\n",
    "directions = ['front view', 'side view', 'top view', 'backside view']\n",
    "\n",
    "directional_prompts = [prompt + ', ' + direction for direction in directions]\n",
    "\n",
    "prompt_embeddings = pipe.encode_prompt(prompt)\n",
    "directional_prompt_embeddings = pipe.encode_prompt(directional_prompts)\n",
    "torch.save(prompt_embeddings,\n",
    "           f'embeddings_{prompt.replace(\" \", \"_\")}.pt')\n",
    "torch.save(directional_prompt_embeddings,\n",
    "           f'directional_embeddings_{prompt.replace(\" \", \"_\")}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f46fc3",
   "metadata": {},
   "source": [
    "Чистим память для последующей работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d517f7e",
   "metadata": {
    "id": "3d517f7e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del text_encoder\n",
    "del pipe\n",
    "flush()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca76d0ea",
   "metadata": {
    "id": "0ca3a57b"
   },
   "source": [
    "prompt_embeddings = torch.load('embeddings_Sonic_the_hedgehog_in_a_form_of_matryoshka_doll.pt')\n",
    "directional_prompt_embeddings = torch.load('directional_embeddings_Sonic_the_hedgehog_in_a_form_of_matryoshka_doll.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34e00a",
   "metadata": {},
   "source": [
    "# Генерация изображений\n",
    "\n",
    "Для начала сравним два подхода к генерации плоских изображений:\n",
    "1. Стандартный подход (последовательное расшумление)\n",
    "2. Генерация с помощью SDS функции потерь\n",
    "\n",
    "Для последнего мы реализуем SDS.\n",
    "\n",
    "\n",
    "Для работы в коллабе мы подгружаем маленькую диффузионную модель \"DeepFloyd/IF-I-M-v1.0\".\n",
    "\n",
    "Лучших результатов удастся добиться с моделью \"DeepFloyd/IF-I-XL-v1.0\", которая будет работать чуть медленнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba69ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "17c9bdf1019e4080830054f03612fc76",
      "6e900894ca85482bb7d6dee96962b984",
      "423d424354244ddf9d50017f749a9780",
      "602a9f0117f348988af105d61cf12781",
      "8f3f634f05e54f05828a1d053bee2830",
      "99265485f42c457dbf9e45273e2bcd71",
      "18198a39d4b84f749e46eb2896108291",
      "6291f7acc0ee4f43bad0ecb825c2dc87",
      "c2d6794778f94b33aa95808bf594e1a8",
      "ec14383bdbb94b45bc6b34a8097d2371",
      "0debb04bd3c546f1871855131e7412ec"
     ]
    },
    "id": "c2ba69ce",
    "outputId": "8cbc55a7-8fa4-4eb9-b594-00050ef942f6"
   },
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    deepfloyd_model,\n",
    "    text_encoder=None,\n",
    "    safety_checker=None,\n",
    "    watermarker=None,\n",
    "    feature_extractor=None,\n",
    "    requires_safety_checker=False,\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"balanced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a4cd8",
   "metadata": {},
   "source": [
    "## Сэмплирование\n",
    "\n",
    "Стандартная генерация сводится к вызову метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49278d1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fc0b37455ae84121965133e06c08ed8a",
      "d8b6167caab5451cbe15179c04dcc7b0",
      "209b26c63e79426783e394f60679751b",
      "ceaa39318c134fadaad62f2c3b424d55",
      "dcb16ac228f64c8cbe1519ae048a85f2",
      "dfe802f1491b482ca6efd77a6374fc2a",
      "4f0d6182a9ab459d81be353d413199b9",
      "5a48925c7ea3413abb9562dd66d7a1e7",
      "29636f4acbaa4897a06bc9bd2c5b2419",
      "764493f36d004fbca6026fa564c91547",
      "2df15445a6c343d8a0bfc03d46e9494e"
     ]
    },
    "id": "a7b257e3",
    "outputId": "fa135d29-ee0e-44ac-a5cd-4c08219bf75a"
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(0)\n",
    "image = pipe(\n",
    "    prompt_embeds=prompt_embeddings[0],\n",
    "    negative_prompt_embeds=prompt_embeddings[1],\n",
    "    output_type=\"pt\",\n",
    "    generator=generator,\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9efde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "8f8014b7",
    "outputId": "2b38d135-71a2-4ec3-a52d-57ae01ec9ab8"
   },
   "outputs": [],
   "source": [
    "from diffusers.utils import pt_to_pil\n",
    "from PIL import Image\n",
    "\n",
    "pil_image = pt_to_pil(image)\n",
    "\n",
    "display(pil_image[0].resize((512, 512), Image.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60302c",
   "metadata": {},
   "source": [
    "А для SDS определим необходимые компоненты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead91324",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe\n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c205ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "89c205ca",
    "outputId": "b09be662-fccb-4202-cbcd-0f11df946eeb"
   },
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    deepfloyd_model,\n",
    "    text_encoder=None,\n",
    "    safety_checker=None,\n",
    "    watermarker=None,\n",
    "    feature_extractor=None,\n",
    "    requires_safety_checker=False,\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"balanced\"\n",
    ")\n",
    "\n",
    "unet = pipe.unet.eval()\n",
    "scheduler = pipe.scheduler\n",
    "num_train_timesteps = scheduler.config.num_train_timesteps\n",
    "alphas = scheduler.alphas_cumprod.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2bceb2",
   "metadata": {
    "id": "eb2bceb2"
   },
   "source": [
    "Подсчет градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c0778",
   "metadata": {
    "id": "188c0778"
   },
   "outputs": [],
   "source": [
    "@torch.cuda.amp.autocast(enabled=False)\n",
    "def forward_unet(latents, t, encoder_hidden_states):\n",
    "    input_dtype = latents.dtype\n",
    "    return unet(\n",
    "        latents.to(torch.float16),\n",
    "        t.to(torch.float16),\n",
    "        encoder_hidden_states=encoder_hidden_states.to(torch.float16),\n",
    "    ).sample.to(input_dtype)\n",
    "\n",
    "def get_sds_loss(images, prompt_embeddings, min_step=20, max_step=980, guidance_scale=10.):\n",
    "    batch_size = images.shape[0]\n",
    "    # prepare image\n",
    "    latents = F.interpolate(images, (64, 64), mode=\"bilinear\", align_corners=False, antialias=True)\n",
    "    latents = 2. * latents - 1.\n",
    "    # sample ts\n",
    "    t = torch.randint(\n",
    "        min_step,\n",
    "        max_step,\n",
    "        [batch_size],\n",
    "        dtype=torch.long,\n",
    "        device=torch.device('cuda:0'))\n",
    "    # predict noise\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn_like(latents).to(torch.device('cuda:0'))\n",
    "        latents_noisy = scheduler.add_noise(latents, noise, t)\n",
    "        noise_pred = forward_unet(\n",
    "            torch.cat(2 * [latents_noisy]),\n",
    "            torch.cat(2 * [t]),\n",
    "            torch.cat(prompt_embeddings)\n",
    "        )\n",
    "\n",
    "    noise_pred_text, noise_pred_uncond = noise_pred.chunk(2)\n",
    "    noise_pred_text, _ = noise_pred_text.split(3, dim=1)\n",
    "    noise_pred_uncond, _ = noise_pred_uncond.split(3, dim=1)\n",
    "    noise_pred = noise_pred_text + guidance_scale * (\n",
    "        noise_pred_text - noise_pred_uncond\n",
    "    )\n",
    "\n",
    "    w = (1 - alphas[t]).view(-1, 1, 1, 1)\n",
    "    grad = w * (noise_pred - noise)\n",
    "    grad = torch.nan_to_num(grad)\n",
    "\n",
    "    # loss = SpecifyGradient.apply(latents, grad)\n",
    "    target = (latents - grad).detach()\n",
    "    loss_sds = 0.5 * F.mse_loss(latents, target, reduction=\"sum\") / batch_size\n",
    "    return loss_sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50158379",
   "metadata": {
    "id": "50158379"
   },
   "source": [
    "## Генерация картинки с помощью SDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63b0ee",
   "metadata": {
    "id": "1b63b0ee"
   },
   "outputs": [],
   "source": [
    "image = torch.nn.Parameter(torch.full((1, 3, 256, 256), 0.7, device=torch.device('cuda:0')))\n",
    "optimizer = torch.optim.Adam([image], lr=1e-2, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bd56a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "891bd56a",
    "outputId": "223096c9-3353-4939-db02-47f0e86cbdcf"
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(0)\n",
    "\n",
    "try:\n",
    "    for i in range(256):\n",
    "        t_min = 20\n",
    "        t_max = 980\n",
    "        loss = get_sds_loss(image, prompt_embeddings, t_min, t_max)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        image.data = image.data.clamp(0., 1.)\n",
    "        optimizer.zero_grad()\n",
    "        if i % 16 == 0:\n",
    "            fig, ax = plt.subplots(figsize=(5, 5))\n",
    "            ax.imshow(image[0].permute(1, 2, 0).clamp(0., 1.).detach().cpu())\n",
    "            ax.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(image[0].permute(1, 2, 0).clamp(0., 1.).detach().cpu())\n",
    "    ax.axis('off')\n",
    "    clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lr = torch.clone(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aedd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe\n",
    "del unet\n",
    "flush()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.cuda.amp.autocast(enabled=False)\n",
    "def forward_sr_unet(latents, t, encoder_hidden_states, class_labels):\n",
    "    input_dtype = latents.dtype\n",
    "    return unet(\n",
    "        latents.to(torch.float16),\n",
    "        t.to(torch.float16),\n",
    "        encoder_hidden_states=encoder_hidden_states.to(torch.float16),\n",
    "        class_labels=class_labels\n",
    "    ).sample.to(input_dtype)\n",
    "\n",
    "def get_sr_sds_loss(images, prompt_embeddings, min_step=20, max_step=980, guidance_scale=10., lowres_noise_level=0.75, original=None):\n",
    "    batch_size = images.shape[0]\n",
    "    #latents = images\n",
    "    # prepare image\n",
    "    latents = F.interpolate(images, (256, 256), mode=\"bilinear\", align_corners=False)\n",
    "    latents = 2. * latents - 1.\n",
    "    \n",
    "    if original is None:\n",
    "        upscaled = F.interpolate(latents, (64, 64), mode=\"nearest\")#, align_corners=False, antialias=True)\n",
    "        upscaled = F.interpolate(upscaled, (256, 256), mode=\"nearest\")#, align_corners=True).detach()\n",
    "    else:\n",
    "        original = 2. * original - 1.\n",
    "        upscaled = F.interpolate(original, (64, 64), mode=\"nearest\")#, align_corners=False, antialias=True)\n",
    "        upscaled = F.interpolate(upscaled, (256, 256), mode=\"nearest\")#, align_corners=True).detach()\n",
    "    \n",
    "    noise_level = torch.tensor([int(num_train_timesteps * lowres_noise_level)] * upscaled.shape[0],\n",
    "                               device=upscaled.device)\n",
    "    noise_level = torch.cat([noise_level] * 2)\n",
    "    noise = torch.randn_like(upscaled)\n",
    "    upscaled = scheduler.add_noise(upscaled, noise, torch.tensor(int(num_train_timesteps * lowres_noise_level)))\n",
    "    \n",
    "    # sample ts\n",
    "    t = torch.randint(\n",
    "        min_step,\n",
    "        max_step,\n",
    "        [batch_size],\n",
    "        dtype=torch.long,\n",
    "        device=torch.device('cuda:0'))\n",
    "    # predict noise\n",
    "    with torch.no_grad():\n",
    "        #latents.data = latents.data.clamp(-1., 1.)\n",
    "        noise = torch.randn_like(latents).to(torch.device('cuda:0'))\n",
    "        latents_noisy = scheduler.add_noise(latents, noise, t)\n",
    "                             \n",
    "        latent_model_input = torch.cat([latents_noisy, upscaled], dim=1)\n",
    "        latent_model_input = torch.cat([latent_model_input] * 2, dim=0)\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "                             \n",
    "        noise_pred = forward_sr_unet(\n",
    "            latent_model_input,\n",
    "            torch.cat(2 * [t]),\n",
    "            encoder_hidden_states=torch.cat(prompt_embeddings),\n",
    "            class_labels=noise_level\n",
    "        )\n",
    "\n",
    "    noise_pred_text, noise_pred_uncond = noise_pred.chunk(2)\n",
    "    noise_pred_text, _ = noise_pred_text.split(3, dim=1)\n",
    "    noise_pred_uncond, _ = noise_pred_uncond.split(3, dim=1)\n",
    "    noise_pred = noise_pred_text + guidance_scale * (\n",
    "        noise_pred_text - noise_pred_uncond\n",
    "    )\n",
    "\n",
    "    w = (1 - alphas[t]).view(-1, 1, 1, 1)\n",
    "\n",
    "    grad = w * (noise_pred - noise)\n",
    "    grad = torch.nan_to_num(grad)\n",
    "    \n",
    "    target = (latents - grad).detach()\n",
    "    loss_sds = 0.5 * F.mse_loss(latents, target, reduction=\"sum\") / batch_size\n",
    "    return loss_sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.nn.Parameter(torch.clone(image_lr))\n",
    "optimizer = torch.optim.Adam([image], lr=1e-2, weight_decay=0)\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"DeepFloyd/IF-II-M-v1.0\",\n",
    "    text_encoder=None, \n",
    "    safety_checker=None, \n",
    "    watermarker=None,\n",
    "    feature_extractor=None,\n",
    "    requires_safety_checker=False,\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(device)\n",
    "\n",
    "unet = pipe.unet.eval()\n",
    "scheduler = pipe.scheduler\n",
    "num_train_timesteps = scheduler.config.num_train_timesteps\n",
    "alphas = scheduler.alphas_cumprod.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e67431",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(1)\n",
    "\n",
    "try:\n",
    "    for i in range(1024):\n",
    "        t_min = 20\n",
    "        t_max = 980\n",
    "        loss = get_sr_sds_loss(image, prompt_embeddings, t_min, t_max, original=image_lr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % 16 == 0:\n",
    "            fig, ax = plt.subplots(figsize=(5, 5))\n",
    "            ax.imshow(image[0].permute(1, 2, 0).clamp(0., 1.).detach().cpu())\n",
    "            ax.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(image[0].permute(1, 2, 0).clamp(0., 1.).detach().cpu())\n",
    "    ax.axis('off')\n",
    "    clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafac296",
   "metadata": {
    "id": "eafac296"
   },
   "source": [
    "# 3D\n",
    "\n",
    "Переходим к аналогичной процедуре обучения, но в 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe\n",
    "del unet\n",
    "flush()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801beac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    deepfloyd_model,\n",
    "    text_encoder=None,\n",
    "    safety_checker=None,\n",
    "    watermarker=None,\n",
    "    feature_extractor=None,\n",
    "    requires_safety_checker=False,\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"balanced\"\n",
    ")\n",
    "\n",
    "unet = pipe.unet.eval()\n",
    "scheduler = pipe.scheduler\n",
    "num_train_timesteps = scheduler.config.num_train_timesteps\n",
    "alphas = scheduler.alphas_cumprod.to(torch.device('cuda:0'))\n",
    "\n",
    "@torch.cuda.amp.autocast(enabled=False)\n",
    "def forward_unet(latents, t, encoder_hidden_states):\n",
    "    input_dtype = latents.dtype\n",
    "    return unet(\n",
    "        latents.to(torch.float16),\n",
    "        t.to(torch.float16),\n",
    "        encoder_hidden_states=encoder_hidden_states.to(torch.float16),\n",
    "    ).sample.to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb10d30",
   "metadata": {
    "id": "afb10d30"
   },
   "outputs": [],
   "source": [
    "def get_pixel_colors(points, texture, light_source):\n",
    "    albedo = texture(points)\n",
    "    normals = calculate_normals(points)\n",
    "    light_source = light_source.view(points.shape[0], 1, 1, 3)\n",
    "    light_dir = F.normalize(light_source - points, dim=-1)\n",
    "    # Lambert's cosine law\n",
    "    shadow_coefficient = (normals * light_dir).sum(-1, keepdim=True).clamp(0.)\n",
    "    # Does the point see the light source?\n",
    "    light_rays = {'origins': points,\n",
    "                  'directions': F.normalize(light_source - points, dim=-1)}\n",
    "    in_shadow = calculate_soft_shadow(light_rays)\n",
    "    #in_shadow = 1.0\n",
    "    ambient_light = 0.4\n",
    "    return (albedo * (ambient_light + shadow_coefficient * in_shadow)).clamp(0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41181c",
   "metadata": {
    "id": "ef41181c"
   },
   "outputs": [],
   "source": [
    "matryoshka_texture = Texture(texture_grid=torch.full((1, 3, 128, 128), 0.5),\n",
    "                             background_color=torch.as_tensor([0.85, 0.85, 0.85]),\n",
    "                             resolution=128,\n",
    "                             train_background=False).to(device)\n",
    "optimizer = torch.optim.Adam(matryoshka_texture.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411539f",
   "metadata": {
    "id": "c411539f"
   },
   "outputs": [],
   "source": [
    "def sample_cameras(batch_size, device):\n",
    "    phi = 0.7 * torch.randn(batch_size, device=device).clamp(-torch.pi, torch.pi)\n",
    "    theta = torch.zeros(batch_size, device=device)\n",
    "    camera_target = torch.as_tensor([[0., 0., 1.0]], device=device)\n",
    "    camera_directions = -torch.stack(\n",
    "        [phi.cos() * theta.cos(),\n",
    "         phi.sin() * theta.cos(),\n",
    "         theta.sin()], dim=1\n",
    "    )\n",
    "    camera_origins = camera_target - 3 * camera_directions\n",
    "    embedding_index = torch.full((batch_size,), 0., dtype=torch.int64, device=device) # front\n",
    "    embedding_index = torch.where(phi.abs() > 0.25 * torch.pi,\n",
    "                                  torch.full_like(embedding_index, 1), # size\n",
    "                                  embedding_index) # side\n",
    "    embedding_index = torch.where(phi.abs() > 0.75 * torch.pi,\n",
    "                                  torch.full_like(embedding_index, 3), # backside\n",
    "                                  embedding_index)\n",
    "    embedding_index = torch.where(theta > 0.25 * torch.pi,\n",
    "                                  torch.full_like(embedding_index, 2), # top\n",
    "                                  embedding_index)\n",
    "    return camera_origins, camera_directions, embedding_index\n",
    "\n",
    "def sample_light(batch_size, device):\n",
    "    phi = (0.3 * torch.randn((batch_size,), device=device)).clamp(-torch.pi, torch.pi)\n",
    "    return 4. * torch.cat([phi.cos(), phi.sin(), torch.ones_like(phi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496b443",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "5496b443",
    "outputId": "b5fd3294-a303-4715-f2b8-1beb2f6269ad"
   },
   "outputs": [],
   "source": [
    "camera_origin, camera_direction, embedding_index = sample_cameras(1, device)\n",
    "light_source = sample_light(1, device)\n",
    "\n",
    "rendered_image = render(camera_origin,\n",
    "                        camera_direction,\n",
    "                        get_pixel_colors,\n",
    "                        matryoshka_texture,\n",
    "                        light_source,\n",
    "                        resolution=512)\n",
    "\n",
    "plt.imshow(rendered_image[0].detach().cpu())\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jqgYYPbHsen2",
   "metadata": {
    "id": "jqgYYPbHsen2"
   },
   "outputs": [],
   "source": [
    "def plot_texture_and_matryoshka(image, matryoshka_texture):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    matryoshka_texture.matryoshka_grid.data = matryoshka_texture.matryoshka_grid.data.clamp(0.05, 0.95)\n",
    "    ax[0].imshow(torch.movedim(image[0], 0, -1).clamp(0., 1.).detach().cpu())\n",
    "    ax[0].axis('off')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    texture_map = matryoshka_texture.matryoshka_grid.data.cpu()\n",
    "    texture_map = torch.flip(texture_map, (-2,))\n",
    "    ax[1].axis('off')\n",
    "    ax[1].imshow(torch.movedim(texture_map[0], 0, -1), aspect=1.);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241f7cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "0241f7cf",
    "outputId": "f1a9cb2a-db97-4ad6-a281-966e74209b1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(1)\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "for i in range(512):\n",
    "    t_min = 20\n",
    "    t_max = 980\n",
    "    # sample camera\n",
    "    camera_origins, camera_directions, embedding_index = sample_cameras(batch_size, device)\n",
    "    batch_embeddings = [directional_prompt_embeddings[0][embedding_index],\n",
    "                        directional_prompt_embeddings[1][embedding_index]]\n",
    "    # sample light\n",
    "    light_sources = sample_light(batch_size, device)\n",
    "    # sample camera_directions\n",
    "    image = render(camera_origins,\n",
    "                   camera_directions,\n",
    "                   get_pixel_colors,\n",
    "                   matryoshka_texture,\n",
    "                   light_sources,\n",
    "                   resolution=256)\n",
    "    image = torch.movedim(image, -1, 1)\n",
    "    loss = get_sds_loss(image, batch_embeddings, t_min, t_max, guidance_scale=5.)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    matryoshka_texture.matryoshka_grid.data = matryoshka_texture.matryoshka_grid.data.clamp(0., 1.)\n",
    "    if i % 16 == 0:\n",
    "        plot_texture_and_matryoshka(image, matryoshka_texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bad407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533,
     "resources": {
      "http://localhost:8080/test_renderer_0.mp4": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "59bad407",
    "outputId": "f6b19291-c7ec-4fb2-db85-c25de3a454dc"
   },
   "outputs": [],
   "source": [
    "images = render_validation_frames(get_pixel_colors, matryoshka_texture, chunk_size=1)\n",
    "save_video(images, 'test_renderer.mp4')\n",
    "\n",
    "Video(\"test_renderer.mp4\", width=512, height=512, html_attributes='loop autoplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f523ce1",
   "metadata": {},
   "source": [
    "# Upres Matryoshka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa566cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe\n",
    "del unet\n",
    "flush()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_original = Texture(texture_grid=matryoshka_texture.matryoshka_grid,\n",
    "                           background_color=torch.as_tensor([0.83, 0.85, 0.87]),\n",
    "                           resolution=128,\n",
    "                           train_background=False).to(device)\n",
    "\n",
    "matryoshka_texture = Texture(texture_grid=matryoshka_texture.matryoshka_grid,\n",
    "                           background_color=torch.as_tensor([0.83, 0.85, 0.87]),\n",
    "                           resolution=256,\n",
    "                           train_background=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa838971",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"DeepFloyd/IF-II-M-v1.0\",\n",
    "    text_encoder=None, \n",
    "    safety_checker=None, \n",
    "    watermarker=None,\n",
    "    feature_extractor=None,\n",
    "    requires_safety_checker=False,\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(device)\n",
    "\n",
    "unet = pipe.unet.eval()\n",
    "scheduler = pipe.scheduler\n",
    "num_train_timesteps = scheduler.config.num_train_timesteps\n",
    "alphas = scheduler.alphas_cumprod.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(matryoshka_texture.parameters(), lr=1e-2)\n",
    "generator = torch.Generator().manual_seed(1)\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "for i in range(512):\n",
    "    t_min = 20\n",
    "    t_max = 980\n",
    "    # sample camera\n",
    "    camera_origins, camera_directions, embedding_index = sample_cameras(batch_size, device)\n",
    "    batch_embeddings = [directional_prompt_embeddings[0][embedding_index],\n",
    "                        directional_prompt_embeddings[1][embedding_index]]\n",
    "    # sample light\n",
    "    light_sources = sample_light(batch_size, device)\n",
    "    # sample camera_directions\n",
    "    original_image = render(camera_origins,\n",
    "                            camera_directions,\n",
    "                            get_pixel_colors,\n",
    "                            texture_original,\n",
    "                            light_sources,\n",
    "                            resolution=64).detach()\n",
    "    image = render(camera_origins,\n",
    "                   camera_directions,\n",
    "                   get_pixel_colors,\n",
    "                   matryoshka_texture,\n",
    "                   light_sources,\n",
    "                   resolution=256)\n",
    "    image = torch.movedim(image, -1, 1)\n",
    "    original_image = torch.movedim(original_image, -1, 1)\n",
    "    loss = get_sr_sds_loss(image, batch_embeddings, t_min, t_max, guidance_scale=10., original=original_image)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    matryoshka_texture.matryoshka_grid.data = matryoshka_texture.matryoshka_grid.data.clamp(0., 1.)\n",
    "    if i % 16 == 0:\n",
    "        plot_texture_and_matryoshka(image, matryoshka_texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba65fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = render_validation_frames(get_pixel_colors, matryoshka_texture, chunk_size=1)\n",
    "save_video(images, 'test_renderer.mp4')\n",
    "\n",
    "Video(\"test_renderer.mp4\", width=512, height=512, html_attributes='loop autoplay')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083b67069095484f84b0377d21801c1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0debb04bd3c546f1871855131e7412ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f6d14ec2c814656b7c02c1ba64080b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "12c6025145ec402e89baaca6f8c470aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15b26e55b9424ccc87b4eebe547ef8b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17c9bdf1019e4080830054f03612fc76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e900894ca85482bb7d6dee96962b984",
       "IPY_MODEL_423d424354244ddf9d50017f749a9780",
       "IPY_MODEL_602a9f0117f348988af105d61cf12781"
      ],
      "layout": "IPY_MODEL_8f3f634f05e54f05828a1d053bee2830"
     }
    },
    "18198a39d4b84f749e46eb2896108291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c2de2ddf2734412995b6165bc43dfd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e837aff804e4fba9740fed239165ae6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_874c19d1eac04e69ad14867c36eda1c7",
       "IPY_MODEL_893b2303e9684ff48938cde3406b41da",
       "IPY_MODEL_f287b1f5940f447697ffb1d1bf8d7bdb"
      ],
      "layout": "IPY_MODEL_15b26e55b9424ccc87b4eebe547ef8b8"
     }
    },
    "209b26c63e79426783e394f60679751b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a48925c7ea3413abb9562dd66d7a1e7",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29636f4acbaa4897a06bc9bd2c5b2419",
      "value": 100
     }
    },
    "29636f4acbaa4897a06bc9bd2c5b2419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a519a4bd32346cfaa604df2dd41eb54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2df15445a6c343d8a0bfc03d46e9494e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "423d424354244ddf9d50017f749a9780": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6291f7acc0ee4f43bad0ecb825c2dc87",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2d6794778f94b33aa95808bf594e1a8",
      "value": 3
     }
    },
    "4f0d6182a9ab459d81be353d413199b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a48925c7ea3413abb9562dd66d7a1e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "602a9f0117f348988af105d61cf12781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec14383bdbb94b45bc6b34a8097d2371",
      "placeholder": "​",
      "style": "IPY_MODEL_0debb04bd3c546f1871855131e7412ec",
      "value": " 3/3 [00:04&lt;00:00, 16.81it/s]"
     }
    },
    "6291f7acc0ee4f43bad0ecb825c2dc87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e900894ca85482bb7d6dee96962b984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99265485f42c457dbf9e45273e2bcd71",
      "placeholder": "​",
      "style": "IPY_MODEL_18198a39d4b84f749e46eb2896108291",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "764493f36d004fbca6026fa564c91547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "874c19d1eac04e69ad14867c36eda1c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083b67069095484f84b0377d21801c1e",
      "placeholder": "​",
      "style": "IPY_MODEL_12c6025145ec402e89baaca6f8c470aa",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "893b2303e9684ff48938cde3406b41da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a519a4bd32346cfaa604df2dd41eb54",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f6d14ec2c814656b7c02c1ba64080b4",
      "value": 6
     }
    },
    "8f3f634f05e54f05828a1d053bee2830": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94fcd7af3a464cbd905b57817aa324c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99265485f42c457dbf9e45273e2bcd71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2d6794778f94b33aa95808bf594e1a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ceaa39318c134fadaad62f2c3b424d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_764493f36d004fbca6026fa564c91547",
      "placeholder": "​",
      "style": "IPY_MODEL_2df15445a6c343d8a0bfc03d46e9494e",
      "value": " 100/100 [00:06&lt;00:00, 13.07it/s]"
     }
    },
    "d8b6167caab5451cbe15179c04dcc7b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfe802f1491b482ca6efd77a6374fc2a",
      "placeholder": "​",
      "style": "IPY_MODEL_4f0d6182a9ab459d81be353d413199b9",
      "value": "100%"
     }
    },
    "dcb16ac228f64c8cbe1519ae048a85f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfe802f1491b482ca6efd77a6374fc2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec14383bdbb94b45bc6b34a8097d2371": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f287b1f5940f447697ffb1d1bf8d7bdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94fcd7af3a464cbd905b57817aa324c4",
      "placeholder": "​",
      "style": "IPY_MODEL_1c2de2ddf2734412995b6165bc43dfd3",
      "value": " 6/6 [00:15&lt;00:00,  4.04s/it]"
     }
    },
    "fc0b37455ae84121965133e06c08ed8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8b6167caab5451cbe15179c04dcc7b0",
       "IPY_MODEL_209b26c63e79426783e394f60679751b",
       "IPY_MODEL_ceaa39318c134fadaad62f2c3b424d55"
      ],
      "layout": "IPY_MODEL_dcb16ac228f64c8cbe1519ae048a85f2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
