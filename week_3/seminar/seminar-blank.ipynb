{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4cf4a2",
   "metadata": {},
   "source": [
    "A wigglegram is a short GIF that allows to percieve depth through parallax as shown below:\n",
    "\n",
    "<img src=\"wigglegram_example.gif \" width=\"500\"/>\n",
    "[Image ource.]( https://www.reddit.com/r/wigglegrams/comments/jm4m2v/seagulls_nimslo/)\n",
    "\n",
    "Such GIFs are usually captured with a custom analog camera, e.g. [Nishika N8000](https://en.wikipedia.org/wiki/Nimslo):\n",
    "<img src=\"camera.jpg \" width=\"500\"/>\n",
    "\n",
    "Our goal today is to generate a wigglegram using a single image.\n",
    "\n",
    "The repository contrains a test image ```cat.jpg``` and a metric depth map ```cat_deapth_map.png``` generated with [ZoeDepth](https://huggingface.co/spaces/shariqfarooq/ZoeDepth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee099c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "def dehomogenize_points(points):\n",
    "    return points[..., :-1] / (points[..., -1:] + 1e-8 * torch.sign(points[..., -1:]))\n",
    "\n",
    "def homogenize_points(points):\n",
    "    last_coordinate = torch.ones_like(points[..., -1:])\n",
    "    return torch.cat((points, last_coordinate), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread('cat.jpeg')[::2, ::2] / 255\n",
    "image = torch.tensor(image, dtype=torch.float)\n",
    "depths = plt.imread('cat_depth_map.png')[::2, ::2] * 256\n",
    "depths = torch.tensor(depths, dtype=torch.float)\n",
    "h, w, c = image.shape\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(image)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(depths)\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute intrinsic matrix\n",
    "# this one is for iphone 13 rear camera\n",
    "K = torch.tensor([\n",
    "    [26 / 24 ,     0., 0.5],\n",
    "    [     0., 26 / 36, 0.5],\n",
    "    [     0.,      0., 1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad802163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud(\n",
    "    K: Float[Tensor, '3 3'],\n",
    "    depths: Float[Tensor, 'h w 3'],\n",
    "    h: int,\n",
    "    w: int\n",
    ") -> Float[Tensor, 'h w 3']:\n",
    "    \"\"\" Generate a 3D point cloud using an image with [0, 1] x [0, 1] coordinates.\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(\n",
    "    image: Float[Tensor, 'h w 3'],\n",
    "    h: int,\n",
    "    w: int,\n",
    ") -> Float[Tensor, 'h w 3']:\n",
    "    \"\"\"Create an array with pixel colors.\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f2ed114",
   "metadata": {},
   "source": [
    "# you can try to visualize the point cloud for debugging\n",
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(\n",
    "    get_point_cloud(K, depths, h, w).view(-1, 3)\n",
    ")\n",
    "pcd.colors = o3d.utility.Vector3dVector(\n",
    "    get_colors(image, h, w).view(-1, 3)\n",
    ")\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64562384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_w2c(delta_x: float) -> Float[Tensor, '4 4']:\n",
    "    \"\"\"Returns a 4x4 world to camera matrix that moves the camera along x axis.\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(\n",
    "    points_3d: Float[Tensor, '... 3'],\n",
    "    c_w2c: Float[Tensor, '4 4'],\n",
    "    K: Float[Tensor, '3 3']\n",
    ") -> Float[Tensor, '... 3']:\n",
    "    \"\"\"Projects point cloud onto a new screen defined by c_w2c.\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = get_point_cloud(K, depths, h, w)\n",
    "new_points_2d = project_points(points_3d, get_c_w2c(-1e-1), K)\n",
    "colors = get_colors(image, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43248a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frame(\n",
    "    points: Float[Tensor, 'h w 3'],\n",
    "    colors: Float[Tensor, 'h w 3'], \n",
    "    h: int, \n",
    "    w: int\n",
    ") -> Float[Tensor, 'h w 3']:\n",
    "    # filter points outside of the frame\n",
    "    # create canvas\n",
    "    # fill the canvas\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e492d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try for a single frame\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(generate_frame(new_points_2d, colors, h // 2, w // 2))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate multiple frames\n",
    "for i, delta_x in enumerate([-0.1, -0.05, 0., 0.05, 0.1]):\n",
    "    new_points_2d = project_points(points_3d, get_c_w2c(delta_x), K)\n",
    "    frame = generate_frame(new_points_2d, colors, h // 2, w // 2)\n",
    "    plt.imsave(f'frame_{i}.png', frame.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0746840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a gif!\n",
    "!ffmpeg -i frame_%d.png -filter_complex \"[0]reverse[r];[0][r]concat=n=2:v=1:a=0\" output.gif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
