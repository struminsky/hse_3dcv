{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4cf4a2",
   "metadata": {},
   "source": [
    "A wigglegram is a short GIF that allows to percieve depth through parallax as shown below:\n",
    "\n",
    "<img src=\"wigglegram_example.gif \" width=\"500\"/>\n",
    "[Image ource.]( https://www.reddit.com/r/wigglegrams/comments/jm4m2v/seagulls_nimslo/)\n",
    "\n",
    "Such GIFs are usually captured with a custom analog camera, e.g. [Nishika N8000](https://en.wikipedia.org/wiki/Nimslo):\n",
    "<img src=\"camera.jpg \" width=\"500\"/>\n",
    "\n",
    "Our goal today is to generate a wigglegram using a single image and a depth map. The repository contrains a test image ```cat.jpg``` and a metric depth map ```cat_deapth_map.png``` generated with [ZoeDepth](https://huggingface.co/spaces/shariqfarooq/ZoeDepth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee099c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "def dehomogenize_points(points):\n",
    "    return points[..., :-1] / (points[..., -1:] + 1e-8 * torch.sign(points[..., -1:]))\n",
    "\n",
    "def homogenize_points(points):\n",
    "    last_coordinate = torch.ones_like(points[..., -1:])\n",
    "    return torch.cat((points, last_coordinate), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread('images/cat.jpeg')[::2, ::2] / 255\n",
    "image = torch.tensor(image, dtype=torch.float)\n",
    "depths = plt.imread('images/cat_depth_map.png')[::2, ::2] * 256\n",
    "depths = torch.tensor(depths, dtype=torch.float)\n",
    "h, w, c = image.shape\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "ax[0].imshow(image)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(depths)\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute intrinsic matrix\n",
    "# this one is for iphone 13 rear camera\n",
    "K = torch.tensor([\n",
    "    [26 / 24 ,     0., 0.5],\n",
    "    [     0., 26 / 36, 0.5],\n",
    "    [     0.,      0., 1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud(\n",
    "    K: Float[Tensor, '3 3'],\n",
    "    depths: Float[Tensor, 'h w 3'],\n",
    "    h: int,\n",
    "    w: int\n",
    ") -> Float[Tensor, 'h w 3']:\n",
    "    \"\"\"Generate a 3D point cloud using an image with [0, 1] x [0, 1] coordinates.\"\"\"\n",
    "    x = torch.linspace(0, 1, w)\n",
    "    y = torch.linspace(0, 1, h)\n",
    "    xs, ys = torch.meshgrid([x, y], indexing='xy')\n",
    "    points = homogenize_points(torch.stack([xs, ys], dim=-1))\n",
    "    return depths[..., None] * (points @ torch.linalg.inv(K).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(\n",
    "    image: Float[Tensor, 'h w 3'],\n",
    "    h: int,\n",
    "    w: int,\n",
    ") -> Float[Tensor, 'h w 3']:\n",
    "    \"\"\"Create an array with pixel colors.\"\"\"\n",
    "    # initialize image points\n",
    "    x = torch.linspace(-1., 1., w)\n",
    "    y = torch.linspace(-1., 1., h)\n",
    "    xs, ys = torch.meshgrid([x, y], indexing='xy')\n",
    "    points = torch.stack([xs, ys], dim=-1)\n",
    "    # prepare for grid sample\n",
    "    image = torch.permute(image, (2, 0, 1)).unsqueeze(0)\n",
    "    points = points.view(1, 1, -1, 2)\n",
    "    colors = torch.nn.functional.grid_sample(image, points, align_corners=True)\n",
    "    return torch.permute(colors.view(3, h, w,), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc9c2b4e",
   "metadata": {},
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(\n",
    "    get_point_cloud(K, depths, h, w).view(-1, 3)\n",
    ")\n",
    "pcd.colors = o3d.utility.Vector3dVector(\n",
    "    get_colors(image, h, w).view(-1, 3)\n",
    ")\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_w2c(delta_x: float) -> Float[Tensor, '4 4']:\n",
    "    \"\"\"Returns a 4x4 world to camera matrix that moves the camera along x axis.\"\"\"\n",
    "    return torch.tensor([\n",
    "        [1., 0., 0., delta_x],\n",
    "        [0., 1., 0.,      0.],\n",
    "        [0., 0., 1.,      0.],\n",
    "        [0., 0., 0.,      1.]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(\n",
    "    points_3d: Float[Tensor, '... 3'],\n",
    "    c_w2c: Float[Tensor, '4 4'],\n",
    "    K: Float[Tensor, '3 3']\n",
    ") -> Float[Tensor, '... 3']:\n",
    "    \"\"\"Projects point cloud onto a new screen defined by c_w2c.\"\"\"\n",
    "    return dehomogenize_points(\n",
    "        (homogenize_points(points_3d) @ c_w2c.T)[..., :3] @ K.T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = get_point_cloud(K, depths, h, w)\n",
    "new_points_2d = project_points(points_3d, get_c_w2c(-1e-1), K)\n",
    "colors = get_colors(image, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frame(\n",
    "    points: Float[Tensor, 'h w 3'],\n",
    "    colors: Float[Tensor, 'h w 3'], \n",
    "    h: int, \n",
    "    w: int\n",
    ") -> Float[Tensor, 'h w 3']:\n",
    "    # filter points outside of the frame\n",
    "    points = points.view(-1, 2)\n",
    "    colors = colors.view(-1, 3)\n",
    "    mask = (\n",
    "        (points[..., 0] <= 1.)\n",
    "        * (points[..., 0] >= 0.)\n",
    "        * (points[..., 1] <= 1.)\n",
    "        * (points[..., 1] >= 0.)\n",
    "    )\n",
    "    points = points[mask]\n",
    "    colors = colors[mask]\n",
    "    # create canvas\n",
    "    canvas = torch.zeros(h, w, 3)\n",
    "    # fill the canvas\n",
    "    canvas[(points[:, 1] * (h - 1)).floor().long(), (points[:, 0] * (w - 1)).floor().long()] = colors\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(generate_frame(new_points_2d, colors, h // 2, w // 2))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, delta_x in enumerate([-0.1, -0.05, 0., 0.05, 0.1]):\n",
    "    new_points_2d = project_points(points_3d, get_c_w2c(delta_x), K)\n",
    "    frame = generate_frame(new_points_2d, colors, h // 2, w // 2)\n",
    "    plt.imsave(f'images/frame_{i}.png', frame.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e79457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a gif!\n",
    "!ffmpeg -i ./images/frame_%d.png -filter_complex \"[0]reverse[r];[0][r]concat=n=2:v=1:a=0\" output.gif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
